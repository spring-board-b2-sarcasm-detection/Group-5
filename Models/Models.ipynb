{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Iieiq_pl9EXV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploring Different Models"
      ],
      "metadata": {
        "id": "V0_l2clhKD_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('t_dataset.csv', index_col=False)\n",
        "texts = df['Tweet']\n",
        "labels = df['Sarcasm'].map({'yes': 1, 'no': 0})"
      ],
      "metadata": {
        "id": "Alv7c9UGfffY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "vCKJZZbZKkso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters (adjust as needed)\n",
        "max_len = 100  # Maximum sequence length\n",
        "vocab_size = 10000  # Limit on the number of words in vocabulary\n",
        "embedding_dim = 128  # Dimensionality of word embeddings\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Padding sequences to a fixed length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4D5km1_8d0X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Bidirectional LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Use Bidirectional LSTM\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Train the model\n",
        "# The model definition and compilation needs to happen before calling fit\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "# Evaluate the model (replace with desired evaluation metrics)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on new data (optional)\n",
        "new_text = \"My mom asked me this qquestion as well.\"  # Replace with your text\n",
        "sequence = tokenizer.texts_to_sequences([new_text])\n",
        "padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "prediction = model.predict(padded_sequence)\n",
        "if prediction > 0.5:\n",
        "    print(\"This text is predicted to be sarcastic.\")\n",
        "else:\n",
        "    print(\"This text is predicted to be non-sarcastic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj63E4JaTpQQ",
        "outputId": "340f72ec-fea8-46ea-8f12-99c32eac32dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 29s 283ms/step - loss: 0.5937 - accuracy: 0.6820 - val_loss: 0.4211 - val_accuracy: 0.8090\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 19s 248ms/step - loss: 0.3604 - accuracy: 0.8461 - val_loss: 0.4589 - val_accuracy: 0.7973\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 20s 273ms/step - loss: 0.1838 - accuracy: 0.9337 - val_loss: 0.5383 - val_accuracy: 0.7856\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 19s 250ms/step - loss: 0.0983 - accuracy: 0.9690 - val_loss: 0.7084 - val_accuracy: 0.7538\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 19s 248ms/step - loss: 0.0636 - accuracy: 0.9836 - val_loss: 0.8097 - val_accuracy: 0.7722\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 20s 265ms/step - loss: 0.0568 - accuracy: 0.9857 - val_loss: 0.9303 - val_accuracy: 0.7487\n",
            "19/19 [==============================] - 1s 52ms/step - loss: 0.9303 - accuracy: 0.7487\n",
            "Test Loss: 0.9303, Accuracy: 0.7487\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "This text is predicted to be non-sarcastic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2) GRUs"
      ],
      "metadata": {
        "id": "MwWsW8yCUcq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GRU model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(GRU(64, return_sequences=True))  # GRU layer with return_sequences=True\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(32))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model (replace with desired evaluation metrics)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on new data (optional)\n",
        "new_text = \"My mom asked me this qquestion as well.\"  # Replace with your text\n",
        "sequence = tokenizer.texts_to_sequences([new_text])\n",
        "padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "prediction = model.predict(padded_sequence)\n",
        "if prediction > 0.5:\n",
        "    print(\"This text is predicted to be sarcastic.\")\n",
        "else:\n",
        "    print(\"This text is predicted to be non-sarcastic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP2S3ao4U1jU",
        "outputId": "143d937f-9d94-4a52-ae43-32da7696283a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 16s 145ms/step - loss: 0.5986 - accuracy: 0.6846 - val_loss: 0.4537 - val_accuracy: 0.8007\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 10s 133ms/step - loss: 0.3472 - accuracy: 0.8498 - val_loss: 0.4949 - val_accuracy: 0.7806\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 11s 146ms/step - loss: 0.1680 - accuracy: 0.9337 - val_loss: 0.6661 - val_accuracy: 0.7471\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 11s 146ms/step - loss: 0.0771 - accuracy: 0.9715 - val_loss: 0.8426 - val_accuracy: 0.7370\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 12s 155ms/step - loss: 0.0499 - accuracy: 0.9853 - val_loss: 0.9671 - val_accuracy: 0.7471\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 9s 125ms/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 1.0915 - val_accuracy: 0.7219\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 11s 145ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 1.1591 - val_accuracy: 0.7337\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 11s 147ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 1.3188 - val_accuracy: 0.7554\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 11s 145ms/step - loss: 0.0172 - accuracy: 0.9929 - val_loss: 1.2690 - val_accuracy: 0.7353\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 9s 125ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 1.3754 - val_accuracy: 0.7270\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.3754 - accuracy: 0.7270\n",
            "Test Loss: 1.3754, Accuracy: 0.7270\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "This text is predicted to be non-sarcastic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) CNNs with Gated Convolutions"
      ],
      "metadata": {
        "id": "r0VwAi7nVfl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters (adjust as needed)\n",
        "max_len = 100  # Maximum sequence length\n",
        "vocab_size = 10000  # Limit on the number of words in vocabulary\n",
        "embedding_dim = 128  # Dimensionality of word embeddings\n",
        "filter_sizes = [3, 4, 5]  # Kernel window sizes for Gated Convolutions\n",
        "num_filters = 64  # Number of filters in the convolutional layers\n",
        "\n",
        "# Load preprocessed data (replace with your actual data)\n",
        "texts = df['Tweet']  # List to store your text data (sarcastic and non-sarcastic)\n",
        "labels = df['Sarcasm']  # List to store labels (1 for sarcastic, 0 for non-sarcastic)\n",
        "labels = df['Sarcasm'].map({'yes': 1, 'no': 0})\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Padding sequences to a fixed length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Embedding layer (convert words to vectors)\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_len)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "\n",
        "# Gated Convolutional layers (with different kernel window sizes)\n",
        "for filter_size in filter_sizes:\n",
        "    conv_layer = Conv1D(num_filters, filter_size, activation='tanh', padding='same')\n",
        "    gated_conv_layer = Conv1D(num_filters, filter_size, activation='sigmoid', padding='same')\n",
        "    model.add(conv_layer)\n",
        "    model.add(gated_conv_layer)\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "# Global Max Pooling layer\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Dense layers for classification\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model (replace with desired evaluation metrics)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on new data (optional)\n",
        "new_text = \"Sure, let's just add this to my already overflowing to-do list.\"  # Replace with your text\n",
        "sequence = tokenizer.texts_to_sequences([new_text])\n",
        "padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "prediction = model.predict(padded_sequence)\n",
        "if prediction > 0.5:\n",
        "    print(\"This text is predicted to be sarcastic.\")\n",
        "else:\n",
        "    print(\"This text is predicted to be non-sarcastic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AspZ0j6ef_I",
        "outputId": "bbabeef1-cdcd-4d3d-9ffb-4a0853d3c479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 10s 108ms/step - loss: 0.6970 - accuracy: 0.5386 - val_loss: 0.6800 - val_accuracy: 0.5812\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 8s 106ms/step - loss: 0.6938 - accuracy: 0.5352 - val_loss: 0.6811 - val_accuracy: 0.5812\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 7s 91ms/step - loss: 0.6924 - accuracy: 0.5440 - val_loss: 0.6834 - val_accuracy: 0.5812\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 7s 100ms/step - loss: 0.6872 - accuracy: 0.5516 - val_loss: 0.6811 - val_accuracy: 0.5812\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.6889 - accuracy: 0.5596 - val_loss: 0.6771 - val_accuracy: 0.5812\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 8s 112ms/step - loss: 0.5598 - accuracy: 0.7282 - val_loss: 0.5686 - val_accuracy: 0.7353\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.3306 - accuracy: 0.8792 - val_loss: 0.5844 - val_accuracy: 0.7085\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 8s 108ms/step - loss: 0.1953 - accuracy: 0.9325 - val_loss: 0.6811 - val_accuracy: 0.7521\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 7s 91ms/step - loss: 0.1287 - accuracy: 0.9631 - val_loss: 0.7102 - val_accuracy: 0.7203\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 8s 110ms/step - loss: 0.0894 - accuracy: 0.9782 - val_loss: 0.8201 - val_accuracy: 0.7219\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.8201 - accuracy: 0.7219\n",
            "Test Loss: 0.8201, Accuracy: 0.7219\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "This text is predicted to be sarcastic.\n"
          ]
        }
      ]
    }
  ]
}